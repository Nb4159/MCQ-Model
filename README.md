# MCQ-Model
This is a ipynb that can answer MCQ type questions with an accuracy of about 99%. 
This was created for the LLM Science competetion hosted by kaggle. The competetition wanted to create a model that can answer user's questions that can hopefully compete with models that can go upto 10 times its size.  My teammate Prasann(@Prasann2004(Github) ) and I devoted about 2 months in order to come up with this solution. We experimented with a large number of models like llama 7B,Deberta V3,Mistral 7B,etc, however due to technical limitations and lack of adequate amount of knowledge(as this was our first experience with LLMs) we weren't able to incorporate large models like Llama and Mistral. So we sticked to Deberta V3 models. 
The notebook uploaded uses ensemble of 4 models with weights computed using a self devised method. Since the models we used are not yet public, I am using false names to denote them.
Also thanks to everyone on kaggle whose ideas and datasets helped us along the way and made it possible for us to deliver this model.
