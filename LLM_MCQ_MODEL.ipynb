{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Installing Dependencies**"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-27T16:00:43.365679Z","iopub.status.busy":"2023-12-27T16:00:43.365413Z","iopub.status.idle":"2023-12-27T16:03:06.160570Z","shell.execute_reply":"2023-12-27T16:03:06.159605Z","shell.execute_reply.started":"2023-12-27T16:00:43.365652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing ./datasets-2.14.4-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (11.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.14.4) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.4) (1.16.0)\n","Installing collected packages: datasets\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.1.0\n","    Uninstalling datasets-2.1.0:\n","      Successfully uninstalled datasets-2.1.0\n","Successfully installed datasets-2.14.4\n","Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Installing collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n","Processing ./sentence-transformers\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.33.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.1)\n","Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.2)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.9.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.3)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126125 sha256=9a15249abd04bd9d6e5f79fbb7a6cc4a40e4eeac29133f4adcce524aba110b4f\n","  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\n","Successfully built sentence-transformers\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.2.2\n","Processing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n","Installing collected packages: blingfire\n","Successfully installed blingfire-0.1.8\n","Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.33.0\n","    Uninstalling transformers-4.33.0:\n","      Successfully uninstalled transformers-4.33.0\n","Successfully installed transformers-4.31.0\n","Processing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n","Installing collected packages: peft\n","Successfully installed peft-0.4.0\n","Processing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\n","Installing collected packages: trl\n","Successfully installed trl-0.5.0\n","Collecting gradio\n","  Downloading gradio-4.12.0-py3-none-any.whl (16.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.1.1)\n","Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.98.0)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gradio-client==0.8.0 (from gradio)\n","  Downloading gradio_client-0.8.0-py3-none-any.whl (305 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.19.3 (from gradio)\n","  Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.12.0)\n","Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.2)\n","Requirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.0.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\n","Collecting pydantic>=2.0 (from gradio)\n","  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.6.3)\n","Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.8.0->gradio) (2023.9.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n","Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n","Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.12.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.5.0)\n","Collecting pydantic-core==2.14.6 (from pydantic>=2.0->gradio)\n","  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.3)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.4.2)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","INFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.33.0,>=0.29.0 (from fastapi->gradio)\n","  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (3.7.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (2023.7.22)\n","Collecting httpcore==1.* (from httpx->gradio)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (3.4)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->gradio) (1.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.1.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (1.26.15)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.0)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=6b2fb0b41f7398b17afceb2186dced5272349d7f6278f143be4cbdf08d41d79c\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: ffmpy, typing-extensions, tomlkit, semantic-version, python-multipart, httpcore, starlette, pydantic-core, huggingface-hub, httpx, pydantic, gradio-client, fastapi, gradio\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.6.3\n","    Uninstalling typing_extensions-4.6.3:\n","      Successfully uninstalled typing_extensions-4.6.3\n","  Attempting uninstall: tomlkit\n","    Found existing installation: tomlkit 0.12.1\n","    Uninstalling tomlkit-0.12.1:\n","      Successfully uninstalled tomlkit-0.12.1\n","  Attempting uninstall: starlette\n","    Found existing installation: starlette 0.27.0\n","    Uninstalling starlette-0.27.0:\n","      Successfully uninstalled starlette-0.27.0\n","  Attempting uninstall: pydantic-core\n","    Found existing installation: pydantic_core 2.6.3\n","    Uninstalling pydantic_core-2.6.3:\n","      Successfully uninstalled pydantic_core-2.6.3\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.16.4\n","    Uninstalling huggingface-hub-0.16.4:\n","      Successfully uninstalled huggingface-hub-0.16.4\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.9\n","    Uninstalling pydantic-1.10.9:\n","      Successfully uninstalled pydantic-1.10.9\n","  Attempting uninstall: fastapi\n","    Found existing installation: fastapi 0.98.0\n","    Uninstalling fastapi-0.98.0:\n","      Successfully uninstalled fastapi-0.98.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n","chex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\n","ydata-profiling 4.3.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.5.3 which is incompatible.\n","ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fastapi-0.108.0 ffmpy-0.3.1 gradio-4.12.0 gradio-client-0.8.0 httpcore-1.0.2 httpx-0.26.0 huggingface-hub-0.20.1 pydantic-2.3.0 pydantic-core-2.14.6 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.32.0.post1 tomlkit-0.12.0 typing-extensions-4.6.3\n"]}],"source":["!cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n","!pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl\n","!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n","!pip install -U /kaggle/working/sentence-transformers\n","!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n","\n","!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n","!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n","!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\n","!cp -r /kaggle/input/stem-wiki-cohere-no-emb /kaggle/working\n","!cp -r /kaggle/input/all-paraphs-parsed-expanded /kaggle/working/\n","!pip install gradio"]},{"cell_type":"markdown","metadata":{},"source":["# **Importing Necessary Libraries**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:06.163689Z","iopub.status.busy":"2023-12-27T16:03:06.163295Z","iopub.status.idle":"2023-12-27T16:03:18.531996Z","shell.execute_reply":"2023-12-27T16:03:18.531080Z","shell.execute_reply.started":"2023-12-27T16:03:06.163652Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd \n","from datasets import load_dataset, load_from_disk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","from transformers import LongformerTokenizer, LongformerForMultipleChoice\n","import transformers\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import unicodedata\n","import os\n","import gc\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:18.533929Z","iopub.status.busy":"2023-12-27T16:03:18.533270Z","iopub.status.idle":"2023-12-27T16:03:21.872744Z","shell.execute_reply":"2023-12-27T16:03:21.871780Z","shell.execute_reply.started":"2023-12-27T16:03:18.533894Z"},"trusted":true},"outputs":[],"source":["import gradio as gr"]},{"cell_type":"markdown","metadata":{},"source":["# **Implementing RAG**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:21.875510Z","iopub.status.busy":"2023-12-27T16:03:21.874896Z","iopub.status.idle":"2023-12-27T16:03:21.900406Z","shell.execute_reply":"2023-12-27T16:03:21.899622Z","shell.execute_reply.started":"2023-12-27T16:03:21.875482Z"},"trusted":true},"outputs":[],"source":["def SplitList(mylist, chunk_size):\n","    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n","def get_relevant_documents_parsed(df_valid):\n","    df_chunk_size=600\n","    paraphs_parsed_dataset = load_from_disk(\"/kaggle/working/all-paraphs-parsed-expanded\")\n","    modified_texts = paraphs_parsed_dataset.map(lambda example:\n","                                             {'temp_text':\n","                                              f\"{example['title']} {example['section']} {example['text']}\".replace('\\n',\" \").replace(\"'\",\"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         paraphs_parsed_dataset[idx.item()][\"title\"],\n","                         paraphs_parsed_dataset[idx.item()][\"text\"],\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","def get_relevant_documents(df_valid):\n","    df_chunk_size=800\n","    \n","    cohere_dataset_filtered = load_from_disk(\"/kaggle/working/stem-wiki-cohere-no-emb\")\n","    modified_texts = cohere_dataset_filtered.map(lambda example:\n","                                             {'temp_text':\n","                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         cohere_dataset_filtered[idx.item()][\"title\"],\n","                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","def retrieval(df_valid, modified_texts):\n","    \n","    corpus_df_valid = df_valid.apply(lambda row:\n","                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","                                     axis=1).values\n","    vectorizer1 = TfidfVectorizer(ngram_range=(1,4),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words,\n","                                 strip_accents=\"unicode\",sublinear_tf=True)\n","    vectorizer1.fit(corpus_df_valid)\n","    vocab_df_valid = vectorizer1.get_feature_names_out()\n","    vectorizer = TfidfVectorizer(ngram_range=(1,4),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words,\n","                                 vocabulary=vocab_df_valid,\n","                                strip_accents=\"unicode\",sublinear_tf=True)\n","    vectorizer.fit(modified_texts[:500000])\n","    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n","    \n","\n","    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n","\n","    chunk_size = 100000\n","    top_per_chunk = 10\n","    top_per_query = 10\n","\n","    all_chunk_top_indices = []\n","    all_chunk_top_values = []\n","\n","    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n","        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n","        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n","        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n","        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n","\n","        all_chunk_top_indices.append(chunk_top_indices + idx)\n","        all_chunk_top_values.append(chunk_top_values)\n","\n","    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n","    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n","    \n","    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n","    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n","    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n","    \n","    return articles_indices, merged_top_scores\n","def prepare_answering_input(\n","        tokenizer, \n","        question,  \n","        options,   \n","        context,   \n","        max_seq_length=700,\n","        ):\n","        c_plus_q   = context + '\\n' + tokenizer.bos_token + '\\n' + question\n","        c_plus_q_4 = [c_plus_q] * len(options)\n","        tokenized_examples = tokenizer(\n","        c_plus_q_4, options,\n","        max_length=max_seq_length,\n","        padding=\"longest\",\n","        truncation=False,\n","        return_tensors=\"pt\",\n","        )\n","        input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n","        attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n","        example_encoded = {\n","            \"input_ids\": input_ids.to(model.device.index),\n","            \"attention_mask\": attention_mask.to(model.device.index),\n","        }\n","        return example_encoded"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:21.902260Z","iopub.status.busy":"2023-12-27T16:03:21.901968Z","iopub.status.idle":"2023-12-27T16:03:52.170127Z","shell.execute_reply":"2023-12-27T16:03:52.169247Z","shell.execute_reply.started":"2023-12-27T16:03:21.902236Z"},"trusted":true},"outputs":[],"source":["stop_words = ['each', 'you', 'the', 'use', 'used',\n","                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n","                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n","                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n","                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n","                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n","                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n","                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n","                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n","                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n","                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n","                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n","                  'did', 'theirs', 'can', 'those',\n","                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n","                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n","                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n","                  'yours', 'but', 'being', \"wasn't\", 'be']\n","from sklearn.feature_extraction import text\n","stop_words2 = text.ENGLISH_STOP_WORDS\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","stop_words3 = set(nlp.Defaults.stop_words)\n","from gensim.parsing.preprocessing import STOPWORDS\n","stop_words4 = set(STOPWORDS)\n","stop_words = list(stop_words2.union(stop_words,stop_words3,stop_words4))"]},{"cell_type":"markdown","metadata":{},"source":["# **Taking Input**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:52.171806Z","iopub.status.busy":"2023-12-27T16:03:52.171464Z","iopub.status.idle":"2023-12-27T16:03:52.189768Z","shell.execute_reply":"2023-12-27T16:03:52.188463Z","shell.execute_reply.started":"2023-12-27T16:03:52.171775Z"},"trusted":true},"outputs":[],"source":["def get_ans(Question,A,B,C,D,E):\n","    df_valid=pd.DataFrame(data=[[Question,A,B,C,D,E]],columns=['prompt','A','B','C','D','E'])\n","    retrieved_articles_parsed = get_relevant_documents_parsed(df_valid)\n","    gc.collect()\n","    retrieved_articles = get_relevant_documents(df_valid)\n","    gc.collect()\n","    model_dir = \"/kaggle/input/llm-science-run-context-2\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","    model_ckpts = [\n","    \"MCQ_Model_1\",\n","    \"MCQ_Model_2\",\n","    \"MCQ_Model_3\",\n","    \"MCQ_Model_4\",\n","    \"MCQ_Model_5\",\n","    \"MCQ_Model_6\"]\n","    weights=[0.1650775630381324, 0.1766253971639686, 0.09755601447394656, 0.19799713518049877, 0.23401899276203172, 0.12872489738142195]\n","    w=[]\n","    g=0\n","    for i in model_ckpts:\n","        print(i,':',weights[g])\n","        g+=1\n","        predictions = []\n","        submit_ids = []\n","        x=[]\n","        model = AutoModelForMultipleChoice.from_pretrained(i).cuda()\n","        tokenizer = AutoTokenizer.from_pretrained(i)\n","        for index in tqdm(range(df_valid.shape[0])):\n","            columns = df_valid.iloc[index].values\n","            submit_ids.append(columns[0])\n","            question =\"Answer the following questions by eliminating wrong options:\\n\"+ columns[1]\n","            options = [columns[1], columns[2], columns[3], columns[4], columns[5]]\n","            context1 = f\"{retrieved_articles[index][-5][2]}\\n{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\\n{retrieved_articles[index][0][2]}\"\n","            context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n","            inputs1 = prepare_answering_input(\n","                tokenizer=tokenizer, question=question,\n","                options=options, context=context1,\n","                )\n","            inputs2 = prepare_answering_input(\n","                tokenizer=tokenizer, question=question,\n","                options=options, context=context2,\n","                )\n","    \n","            with torch.no_grad():\n","                outputs1 = model(**inputs1)    \n","                losses1 = -outputs1.logits[0].detach().cpu().numpy()\n","                probability1 = torch.softmax(torch.tensor(-losses1), dim=-1)\n","        \n","            with torch.no_grad():\n","                outputs2 = model(**inputs2)\n","                losses2 = -outputs2.logits[0].detach().cpu().numpy()\n","                probability2 = torch.softmax(torch.tensor(-losses2), dim=-1)\n","        \n","            probability_ = (probability1 + probability2)/2\n","            x.append(probability_)\n","        w.append(x)\n","    predict=[]\n","    for i in range(len(w[0])):\n","        predict+=[w[0][i]*weights[0]+w[1][i]*weights[1]+w[2][i]*weights[2]+w[3][i]*weights[3]+w[4][i]*weights[4]+w[5][i]*weights[5]]\n","    for i in predict :\n","        predict = np.array(list(\"ABCDE\"))[np.argsort(i)][-3:].tolist()[::-1]\n","        predictions.append(predict)\n","    predictions = [\" \".join(i) for i in predictions]\n","    return df_valid.loc[0,predictions[0][0]]\n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# **Interface**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T16:03:52.191655Z","iopub.status.busy":"2023-12-27T16:03:52.191041Z","iopub.status.idle":"2023-12-27T16:03:56.924179Z","shell.execute_reply":"2023-12-27T16:03:56.923228Z","shell.execute_reply.started":"2023-12-27T16:03:52.191624Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7860\n","Running on public URL: https://9cfe946c78687f7aa0.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/plain":[]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["demo = gr.Interface(fn=get_ans, inputs=[gr.Textbox('Question'),gr.Textbox('A'),gr.Textbox('B'),gr.Textbox('C'),gr.Textbox('D'),gr.Textbox('E')], outputs=\"text\")\n","demo.launch(share=True,debug=False,inline=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":6169864,"sourceId":54662,"sourceType":"competition"},{"datasetId":2202288,"sourceId":3680037,"sourceType":"datasetVersion"},{"datasetId":2893282,"sourceId":4988409,"sourceType":"datasetVersion"},{"datasetId":3238926,"sourceId":5632975,"sourceType":"datasetVersion"},{"datasetId":3526632,"sourceId":6149251,"sourceType":"datasetVersion"},{"datasetId":3612472,"sourceId":6282487,"sourceType":"datasetVersion"},{"datasetId":3520954,"sourceId":6300474,"sourceType":"datasetVersion"},{"datasetId":3662908,"sourceId":6359012,"sourceType":"datasetVersion"},{"datasetId":3663541,"sourceId":6359953,"sourceType":"datasetVersion"},{"datasetId":3698271,"sourceId":6412625,"sourceType":"datasetVersion"},{"datasetId":3699788,"sourceId":6414848,"sourceType":"datasetVersion"},{"datasetId":3675739,"sourceId":6416468,"sourceType":"datasetVersion"},{"datasetId":3749764,"sourceId":6488993,"sourceType":"datasetVersion"},{"datasetId":3770056,"sourceId":6521141,"sourceType":"datasetVersion"},{"datasetId":3791123,"sourceId":6561651,"sourceType":"datasetVersion"},{"datasetId":3600418,"sourceId":6572938,"sourceType":"datasetVersion"},{"datasetId":612177,"sourceId":7269331,"sourceType":"datasetVersion"},{"sourceId":142033605,"sourceType":"kernelVersion"},{"sourceId":142721048,"sourceType":"kernelVersion"},{"sourceId":142734271,"sourceType":"kernelVersion"},{"sourceId":144700262,"sourceType":"kernelVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
