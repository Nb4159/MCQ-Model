{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ef89e3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-10T13:46:56.952752Z",
     "iopub.status.busy": "2023-10-10T13:46:56.952427Z",
     "iopub.status.idle": "2023-10-10T13:47:31.891087Z",
     "shell.execute_reply": "2023-10-10T13:47:31.889942Z"
    },
    "papermill": {
     "duration": 34.946452,
     "end_time": "2023-10-10T13:47:31.893434",
     "exception": false,
     "start_time": "2023-10-10T13:46:56.946982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./datasets-2.14.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (11.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.0.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.3.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2023.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (6.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.14.4) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (2023.7.22)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.4) (1.16.0)\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "Successfully installed datasets-2.14.4\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n",
    "!pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59f676c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:47:31.903621Z",
     "iopub.status.busy": "2023-10-10T13:47:31.903299Z",
     "iopub.status.idle": "2023-10-10T13:49:31.875809Z",
     "shell.execute_reply": "2023-10-10T13:49:31.874581Z"
    },
    "papermill": {
     "duration": 119.979869,
     "end_time": "2023-10-10T13:49:31.877896",
     "exception": false,
     "start_time": "2023-10-10T13:47:31.898027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.2\r\n",
      "Processing ./sentence-transformers\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.33.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.2)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\r\n",
      "Building wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25l-\b \b\\\b \bdone\r\n",
      "\u001B[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126125 sha256=fec9850782ee63cc694e65e2d5f8f60e36768077c5b99a035543f9dca6b3cde0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-2.2.2\r\n",
      "Processing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\r\n",
      "Installing collected packages: blingfire\r\n",
      "Successfully installed blingfire-0.1.8\r\n",
      "Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.33.0\r\n",
      "    Uninstalling transformers-4.33.0:\r\n",
      "      Successfully uninstalled transformers-4.33.0\r\n",
      "Successfully installed transformers-4.31.0\r\n",
      "Processing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.4.0\r\n",
      "Processing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\r\n",
      "Installing collected packages: trl\r\n",
      "Successfully installed trl-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n",
    "\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bd7c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:49:31.890558Z",
     "iopub.status.busy": "2023-10-10T13:49:31.890245Z",
     "iopub.status.idle": "2023-10-10T13:49:45.313760Z",
     "shell.execute_reply": "2023-10-10T13:49:45.312842Z"
    },
    "papermill": {
     "duration": 13.432251,
     "end_time": "2023-10-10T13:49:45.315846",
     "exception": false,
     "start_time": "2023-10-10T13:49:31.883595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerForMultipleChoice\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e46ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:49:45.328192Z",
     "iopub.status.busy": "2023-10-10T13:49:45.327939Z",
     "iopub.status.idle": "2023-10-10T13:50:08.068224Z",
     "shell.execute_reply": "2023-10-10T13:50:08.066664Z"
    },
    "papermill": {
     "duration": 22.750493,
     "end_time": "2023-10-10T13:50:08.072078",
     "exception": false,
     "start_time": "2023-10-10T13:49:45.321585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/stem-wiki-cohere-no-emb /kaggle/working\n",
    "!cp -r /kaggle/input/all-paraphs-parsed-expanded /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61aa9d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:50:08.166317Z",
     "iopub.status.busy": "2023-10-10T13:50:08.165871Z",
     "iopub.status.idle": "2023-10-10T13:50:08.188737Z",
     "shell.execute_reply": "2023-10-10T13:50:08.187905Z"
    },
    "papermill": {
     "duration": 0.099444,
     "end_time": "2023-10-10T13:50:08.190422",
     "exception": false,
     "start_time": "2023-10-10T13:50:08.090978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitList(mylist, chunk_size):\n",
    "    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n",
    "def get_relevant_documents_parsed(df_valid):\n",
    "    df_chunk_size=500\n",
    "    paraphs_parsed_dataset = load_from_disk(\"/kaggle/working/all-paraphs-parsed-expanded\")\n",
    "    modified_texts = paraphs_parsed_dataset.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              f\"{example['title']} {example['section']} {example['text']}\".replace('\\n',\" \").replace(\"'\",\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"title\"],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"text\"],\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "def get_relevant_documents(df_valid):\n",
    "    df_chunk_size=700\n",
    "    \n",
    "    cohere_dataset_filtered = load_from_disk(\"/kaggle/working/stem-wiki-cohere-no-emb\")\n",
    "    modified_texts = cohere_dataset_filtered.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         cohere_dataset_filtered[idx.item()][\"title\"],\n",
    "                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "def retrieval(df_valid, modified_texts):\n",
    "    \n",
    "    corpus_df_valid = df_valid.apply(lambda row:\n",
    "                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n",
    "                                     axis=1).values\n",
    "    vectorizer1 = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words,\n",
    "                                 strip_accents=\"unicode\",sublinear_tf=True)\n",
    "    vectorizer1.fit(corpus_df_valid)\n",
    "    vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words,\n",
    "                                 vocabulary=vocab_df_valid,\n",
    "                                strip_accents=\"unicode\",sublinear_tf=True)\n",
    "    vectorizer.fit(modified_texts[:500000])\n",
    "    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "    \n",
    "#     vectorizer = BM25()\n",
    "#     vectorizer.fit(corpus_df_valid)\n",
    "#     corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n",
    "\n",
    "    chunk_size = 100000\n",
    "    top_per_chunk = 10\n",
    "    top_per_query = 10\n",
    "\n",
    "    all_chunk_top_indices = []\n",
    "    all_chunk_top_values = []\n",
    "\n",
    "    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n",
    "        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n",
    "        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n",
    "        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n",
    "        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n",
    "\n",
    "        all_chunk_top_indices.append(chunk_top_indices + idx)\n",
    "        all_chunk_top_values.append(chunk_top_values)\n",
    "\n",
    "    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n",
    "    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n",
    "    \n",
    "    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n",
    "    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n",
    "    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n",
    "    \n",
    "    return articles_indices, merged_top_scores\n",
    "def prepare_answering_input(\n",
    "        tokenizer, \n",
    "        question,  \n",
    "        options,   \n",
    "        context,   \n",
    "        max_seq_length=700,\n",
    "        ):\n",
    "        c_plus_q   = context + '\\n' + tokenizer.bos_token + '\\n' + question\n",
    "        c_plus_q_4 = [c_plus_q] * len(options)\n",
    "        tokenized_examples = tokenizer(\n",
    "        c_plus_q_4, options,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"longest\",\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n",
    "        attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n",
    "        example_encoded = {\n",
    "            \"input_ids\": input_ids.to(model.device.index),\n",
    "            \"attention_mask\": attention_mask.to(model.device.index),\n",
    "        }\n",
    "        return example_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f62433e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:50:08.202828Z",
     "iopub.status.busy": "2023-10-10T13:50:08.202499Z",
     "iopub.status.idle": "2023-10-10T13:50:29.511531Z",
     "shell.execute_reply": "2023-10-10T13:50:29.510659Z"
    },
    "papermill": {
     "duration": 21.317713,
     "end_time": "2023-10-10T13:50:29.513672",
     "exception": false,
     "start_time": "2023-10-10T13:50:08.195959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = ['each', 'you', 'the', 'use', 'used',\n",
    "                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n",
    "                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n",
    "                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n",
    "                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n",
    "                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n",
    "                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n",
    "                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n",
    "                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n",
    "                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n",
    "                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n",
    "                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n",
    "                  'did', 'theirs', 'can', 'those',\n",
    "                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n",
    "                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n",
    "                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n",
    "                  'yours', 'but', 'being', \"wasn't\", 'be']\n",
    "from sklearn.feature_extraction import text\n",
    "stop_words2 = text.ENGLISH_STOP_WORDS\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words3 = set(nlp.Defaults.stop_words)\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "stop_words4 = set(STOPWORDS)\n",
    "stop_words = list(stop_words2.union(stop_words,stop_words3,stop_words4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010abd1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:50:29.527014Z",
     "iopub.status.busy": "2023-10-10T13:50:29.526444Z",
     "iopub.status.idle": "2023-10-10T13:50:29.553371Z",
     "shell.execute_reply": "2023-10-10T13:50:29.552614Z"
    },
    "papermill": {
     "duration": 0.035115,
     "end_time": "2023-10-10T13:50:29.555112",
     "exception": false,
     "start_time": "2023-10-10T13:50:29.519997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12463820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:50:29.567476Z",
     "iopub.status.busy": "2023-10-10T13:50:29.566721Z",
     "iopub.status.idle": "2023-10-10T13:50:29.570912Z",
     "shell.execute_reply": "2023-10-10T13:50:29.570133Z"
    },
    "papermill": {
     "duration": 0.012205,
     "end_time": "2023-10-10T13:50:29.572588",
     "exception": false,
     "start_time": "2023-10-10T13:50:29.560383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92c3a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:50:29.584752Z",
     "iopub.status.busy": "2023-10-10T13:50:29.583986Z",
     "iopub.status.idle": "2023-10-10T14:00:07.401006Z",
     "shell.execute_reply": "2023-10-10T14:00:07.399996Z"
    },
    "papermill": {
     "duration": 577.825035,
     "end_time": "2023-10-10T14:00:07.402891",
     "exception": false,
     "start_time": "2023-10-10T13:50:29.577856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433b91f54f1d46da8eb7e6ae3ec7cac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2101279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'isn', 'll', 'm', 'n', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vectorizer vocab is 19346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001B[A\n",
      "  5%|▍         | 1/22 [00:17<06:11, 17.69s/it]\u001B[A\n",
      "  9%|▉         | 2/22 [00:36<06:04, 18.21s/it]\u001B[A\n",
      " 14%|█▎        | 3/22 [00:54<05:49, 18.39s/it]\u001B[A\n",
      " 18%|█▊        | 4/22 [01:12<05:24, 18.04s/it]\u001B[A\n",
      " 23%|██▎       | 5/22 [01:30<05:09, 18.19s/it]\u001B[A\n",
      " 27%|██▋       | 6/22 [01:48<04:47, 17.99s/it]\u001B[A\n",
      " 32%|███▏      | 7/22 [02:07<04:32, 18.19s/it]\u001B[A\n",
      " 36%|███▋      | 8/22 [02:24<04:11, 17.97s/it]\u001B[A\n",
      " 41%|████      | 9/22 [02:42<03:54, 18.07s/it]\u001B[A\n",
      " 45%|████▌     | 10/22 [03:01<03:37, 18.13s/it]\u001B[A\n",
      " 50%|█████     | 11/22 [03:18<03:16, 17.86s/it]\u001B[A\n",
      " 55%|█████▍    | 12/22 [03:36<02:59, 17.99s/it]\u001B[A\n",
      " 59%|█████▉    | 13/22 [03:54<02:40, 17.84s/it]\u001B[A\n",
      " 64%|██████▎   | 14/22 [04:12<02:23, 17.96s/it]\u001B[A\n",
      " 68%|██████▊   | 15/22 [04:29<02:04, 17.78s/it]\u001B[A\n",
      " 73%|███████▎  | 16/22 [04:47<01:47, 17.92s/it]\u001B[A\n",
      " 77%|███████▋  | 17/22 [05:05<01:29, 17.92s/it]\u001B[A\n",
      " 82%|████████▏ | 18/22 [05:23<01:11, 17.80s/it]\u001B[A\n",
      " 86%|████████▋ | 19/22 [05:41<00:53, 17.88s/it]\u001B[A\n",
      " 91%|█████████ | 20/22 [05:58<00:35, 17.76s/it]\u001B[A\n",
      " 95%|█████████▌| 21/22 [06:17<00:17, 17.92s/it]\u001B[A\n",
      "100%|██████████| 22/22 [06:17<00:00, 17.16s/it]\n",
      "100%|██████████| 1/1 [07:44<00:00, 464.91s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_articles_parsed = get_relevant_documents_parsed(df_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a91481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:00:07.465950Z",
     "iopub.status.busy": "2023-10-10T14:00:07.465633Z",
     "iopub.status.idle": "2023-10-10T14:10:08.495185Z",
     "shell.execute_reply": "2023-10-10T14:10:08.493922Z"
    },
    "papermill": {
     "duration": 601.041973,
     "end_time": "2023-10-10T14:10:08.497592",
     "exception": false,
     "start_time": "2023-10-10T14:00:07.455619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1383cb519c4893821684f647f15545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2781652 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vectorizer vocab is 19346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▎         | 1/28 [00:11<05:10, 11.51s/it]\u001B[A\n",
      "  7%|▋         | 2/28 [00:22<04:52, 11.25s/it]\u001B[A\n",
      " 11%|█         | 3/28 [00:34<04:45, 11.40s/it]\u001B[A\n",
      " 14%|█▍        | 4/28 [00:44<04:24, 11.04s/it]\u001B[A\n",
      " 18%|█▊        | 5/28 [00:55<04:09, 10.86s/it]\u001B[A\n",
      " 21%|██▏       | 6/28 [01:06<04:02, 11.00s/it]\u001B[A\n",
      " 25%|██▌       | 7/28 [01:16<03:46, 10.81s/it]\u001B[A\n",
      " 29%|██▊       | 8/28 [01:27<03:32, 10.60s/it]\u001B[A\n",
      " 32%|███▏      | 9/28 [01:38<03:24, 10.74s/it]\u001B[A\n",
      " 36%|███▌      | 10/28 [01:48<03:09, 10.52s/it]\u001B[A\n",
      " 39%|███▉      | 11/28 [01:58<02:56, 10.36s/it]\u001B[A\n",
      " 43%|████▎     | 12/28 [02:08<02:47, 10.46s/it]\u001B[A\n",
      " 46%|████▋     | 13/28 [02:18<02:34, 10.31s/it]\u001B[A\n",
      " 50%|█████     | 14/28 [02:28<02:22, 10.20s/it]\u001B[A\n",
      " 54%|█████▎    | 15/28 [02:39<02:15, 10.41s/it]\u001B[A\n",
      " 57%|█████▋    | 16/28 [02:49<02:02, 10.22s/it]\u001B[A\n",
      " 61%|██████    | 17/28 [02:59<01:50, 10.05s/it]\u001B[A\n",
      " 64%|██████▍   | 18/28 [03:09<01:42, 10.23s/it]\u001B[A\n",
      " 68%|██████▊   | 19/28 [03:19<01:30, 10.02s/it]\u001B[A\n",
      " 71%|███████▏  | 20/28 [03:28<01:19,  9.90s/it]\u001B[A\n",
      " 75%|███████▌  | 21/28 [03:39<01:10, 10.09s/it]\u001B[A\n",
      " 79%|███████▊  | 22/28 [03:48<00:59,  9.94s/it]\u001B[A\n",
      " 82%|████████▏ | 23/28 [03:58<00:49,  9.87s/it]\u001B[A\n",
      " 86%|████████▌ | 24/28 [04:08<00:39,  9.79s/it]\u001B[A\n",
      " 89%|████████▉ | 25/28 [04:18<00:29,  9.91s/it]\u001B[A\n",
      " 93%|█████████▎| 26/28 [04:27<00:19,  9.73s/it]\u001B[A\n",
      " 96%|█████████▋| 27/28 [04:36<00:09,  9.55s/it]\u001B[A\n",
      "100%|██████████| 28/28 [04:44<00:00, 10.18s/it]\n",
      "100%|██████████| 1/1 [05:39<00:00, 339.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_articles = get_relevant_documents(df_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c43351e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:10:08.529417Z",
     "iopub.status.busy": "2023-10-10T14:10:08.529108Z",
     "iopub.status.idle": "2023-10-10T14:10:08.696926Z",
     "shell.execute_reply": "2023-10-10T14:10:08.695886Z"
    },
    "papermill": {
     "duration": 0.185814,
     "end_time": "2023-10-10T14:10:08.699304",
     "exception": false,
     "start_time": "2023-10-10T14:10:08.513490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34abc78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:10:08.730998Z",
     "iopub.status.busy": "2023-10-10T14:10:08.730492Z",
     "iopub.status.idle": "2023-10-10T14:10:09.055633Z",
     "shell.execute_reply": "2023-10-10T14:10:09.054534Z"
    },
    "papermill": {
     "duration": 0.343114,
     "end_time": "2023-10-10T14:10:09.057871",
     "exception": false,
     "start_time": "2023-10-10T14:10:08.714757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"/kaggle/input/llm-science-run-context-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87382da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:10:09.089570Z",
     "iopub.status.busy": "2023-10-10T14:10:09.089234Z",
     "iopub.status.idle": "2023-10-10T14:10:09.093972Z",
     "shell.execute_reply": "2023-10-10T14:10:09.092954Z"
    },
    "papermill": {
     "duration": 0.022839,
     "end_time": "2023-10-10T14:10:09.096016",
     "exception": false,
     "start_time": "2023-10-10T14:10:09.073177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpts = [\n",
    "    \"/kaggle/input/model_1\",\n",
    "    \"/kaggle/input/model_2\",\n",
    "\n",
    "    \"/kaggle/input/model_3\",\n",
    "    \"/kaggle/input/model_4\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eeff371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:10:09.126432Z",
     "iopub.status.busy": "2023-10-10T14:10:09.125571Z",
     "iopub.status.idle": "2023-10-10T14:10:09.130432Z",
     "shell.execute_reply": "2023-10-10T14:10:09.129573Z"
    },
    "papermill": {
     "duration": 0.022153,
     "end_time": "2023-10-10T14:10:09.132321",
     "exception": false,
     "start_time": "2023-10-10T14:10:09.110168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights=[0.21417155322179493, 0.22915370782572908, 0.26221393214844196, 0.29446080680403397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefe5c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:10:09.163222Z",
     "iopub.status.busy": "2023-10-10T14:10:09.162384Z",
     "iopub.status.idle": "2023-10-10T14:25:07.317744Z",
     "shell.execute_reply": "2023-10-10T14:25:07.316566Z"
    },
    "papermill": {
     "duration": 898.172938,
     "end_time": "2023-10-10T14:25:07.319946",
     "exception": false,
     "start_time": "2023-10-10T14:10:09.147008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/how-to-use-40k-dataset/model_v3 : 0.21417155322179493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:23<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/abcdefghijklmnopqrstuvwxyz : 0.22915370782572908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llm-science-exam-context-v2-models/deberta-checkpoint-7600/checkpoint-7600 : 0.26221393214844196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/run-sci-1/model_v8 : 0.29446080680403397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "w=[]\n",
    "g=0\n",
    "for i in model_ckpts:\n",
    "    print(i,':',weights[g])\n",
    "    g+=1\n",
    "    predictions = []\n",
    "    submit_ids = []\n",
    "    x=[]\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(i).cuda()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(i)\n",
    "    for index in tqdm(range(df_valid.shape[0])):\n",
    "        columns = df_valid.iloc[index].values\n",
    "        submit_ids.append(columns[0])\n",
    "        question =\"Answer the following questions by eliminating wrong options:\\n\"+ columns[1]\n",
    "        options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "        context1 = f\"{retrieved_articles[index][-5][2]}\\n{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\\n{retrieved_articles[index][0][2]}\"\n",
    "        context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "        inputs1 = prepare_answering_input(\n",
    "            tokenizer=tokenizer, question=question,\n",
    "            options=options, context=context1,\n",
    "            )\n",
    "        inputs2 = prepare_answering_input(\n",
    "            tokenizer=tokenizer, question=question,\n",
    "            options=options, context=context2,\n",
    "            )\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs1 = model(**inputs1)    \n",
    "            losses1 = -outputs1.logits[0].detach().cpu().numpy()\n",
    "            probability1 = torch.softmax(torch.tensor(-losses1), dim=-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs2 = model(**inputs2)\n",
    "            losses2 = -outputs2.logits[0].detach().cpu().numpy()\n",
    "            probability2 = torch.softmax(torch.tensor(-losses2), dim=-1)\n",
    "        \n",
    "        probability_ = (probability1 + probability2)/2\n",
    "        x.append(probability_)\n",
    "    w.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea3ec48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:25:07.416355Z",
     "iopub.status.busy": "2023-10-10T14:25:07.415450Z",
     "iopub.status.idle": "2023-10-10T14:25:07.427371Z",
     "shell.execute_reply": "2023-10-10T14:25:07.426487Z"
    },
    "papermill": {
     "duration": 0.063265,
     "end_time": "2023-10-10T14:25:07.429212",
     "exception": false,
     "start_time": "2023-10-10T14:25:07.365947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for i in range(len(w[0])):\n",
    "    predict+=[w[0][i]*weights[0]+w[1][i]*weights[1]+w[2][i]*weights[2]+w[3][i]*weights[3]]#+w[4][i]*weights[4]+w[5][i]*weights[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecebb9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:25:07.525299Z",
     "iopub.status.busy": "2023-10-10T14:25:07.524604Z",
     "iopub.status.idle": "2023-10-10T14:25:07.555154Z",
     "shell.execute_reply": "2023-10-10T14:25:07.554275Z"
    },
    "papermill": {
     "duration": 0.079844,
     "end_time": "2023-10-10T14:25:07.556850",
     "exception": false,
     "start_time": "2023-10-10T14:25:07.477006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in predict :\n",
    "    predict = np.array(list(\"ABCDE\"))[np.argsort(i)][-3:].tolist()[::-1]\n",
    "    predictions.append(predict)\n",
    "predictions = [\" \".join(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06a44b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:25:07.651422Z",
     "iopub.status.busy": "2023-10-10T14:25:07.650672Z",
     "iopub.status.idle": "2023-10-10T14:25:07.660388Z",
     "shell.execute_reply": "2023-10-10T14:25:07.659612Z"
    },
    "papermill": {
     "duration": 0.058627,
     "end_time": "2023-10-10T14:25:07.662080",
     "exception": false,
     "start_time": "2023-10-10T14:25:07.603453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':submit_ids,'prediction':predictions}).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ebb6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:25:07.754261Z",
     "iopub.status.busy": "2023-10-10T14:25:07.753587Z",
     "iopub.status.idle": "2023-10-10T14:25:07.790014Z",
     "shell.execute_reply": "2023-10-10T14:25:07.788919Z"
    },
    "papermill": {
     "duration": 0.084121,
     "end_time": "2023-10-10T14:25:07.791789",
     "exception": false,
     "start_time": "2023-10-10T14:25:07.707668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@3 score: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "def calculate_MAP3(predictions, labels):\n",
    "    U = len(predictions)  # Number of questions in the test set\n",
    "    MAP3 = 0.0  # Mean Average Precision @ 3\n",
    "\n",
    "    for i in range(U):\n",
    "        n = len(predictions[i])  # Number of predictions per question\n",
    "        relevant_labels = set(labels[i])  # Correct labels for the current question\n",
    "        \n",
    "        precision_sum = 0.0\n",
    "        precision_at_k = 0.0\n",
    "        relevant_count = 0\n",
    "\n",
    "        for k in range(n):\n",
    "            if predictions[i][k] in relevant_labels:\n",
    "                relevant_count += 1\n",
    "                precision_at_k = relevant_count / (k + 1)\n",
    "                precision_sum += precision_at_k\n",
    "                relevant_labels.remove(predictions[i][k])\n",
    "\n",
    "            if relevant_count >= 3:\n",
    "                break\n",
    "\n",
    "        average_precision = precision_sum / min(len(labels[i]), 3)\n",
    "        MAP3 += average_precision\n",
    "    \n",
    "    MAP3 /= U\n",
    "    print(\"MAP@3 score:\", MAP3)\n",
    "from pathlib import Path\n",
    "data_path = Path('/kaggle/input/kaggle-llm-science-exam')\n",
    "\n",
    "training_set = pd.read_csv(data_path / \"train.csv\", index_col='id')\n",
    "labels = [[x] for x in training_set['answer']]\n",
    "calculate_MAP3(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abf5f099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T14:25:07.884786Z",
     "iopub.status.busy": "2023-10-10T14:25:07.884258Z",
     "iopub.status.idle": "2023-10-10T14:25:07.896149Z",
     "shell.execute_reply": "2023-10-10T14:25:07.895293Z"
    },
    "papermill": {
     "duration": 0.059973,
     "end_time": "2023-10-10T14:25:07.897829",
     "exception": false,
     "start_time": "2023-10-10T14:25:07.837856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in predictions:\n",
    "    l.append(i[0])\n",
    "\n",
    "import pandas as pd\n",
    "l1=[]\n",
    "tn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\")\n",
    "for i in tn['answer']:\n",
    "    l1.append(i)\n",
    "    #print(i)\n",
    "sum=0\n",
    "for i in range(len(l)):\n",
    "    if l[i]==l1[i]:\n",
    "        sum+=1\n",
    "        \n",
    "print(sum/len(l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2297.39143,
   "end_time": "2023-10-10T14:25:11.413405",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-10T13:46:54.021975",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "15398f1325934918a23737ede99fd4e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "433b91f54f1d46da8eb7e6ae3ec7cac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4bfd718044b14d318982d26b6a3cf1ab",
        "IPY_MODEL_eccf44ff50fa49b99f8e702cd7e8af33",
        "IPY_MODEL_7d7689bc967747d3b205cf5b9b0fcbdd"
       ],
       "layout": "IPY_MODEL_65967c8f790548de8cebe3eeb80c40c9"
      }
     },
     "45c63b6d9c7f4e5abafd8d9b6b6481ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4bfd718044b14d318982d26b6a3cf1ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bdd40adf999b4bd7a179d4c06d932b89",
       "placeholder": "​",
       "style": "IPY_MODEL_f6b4a25c89b14094bd3dc5733ea854d8",
       "value": "Map (num_proc=2): 100%"
      }
     },
     "4fe19ca6ef7a450b9f0d962510925746": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "60eeb2778f94429883fbc2bfe6628037": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76e10eb695024b538c9332df8aed6d6e",
       "max": 2781652.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4fe19ca6ef7a450b9f0d962510925746",
       "value": 2781652.0
      }
     },
     "65967c8f790548de8cebe3eeb80c40c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76e10eb695024b538c9332df8aed6d6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d7689bc967747d3b205cf5b9b0fcbdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cfcc186a07414805964c70ff1ea17042",
       "placeholder": "​",
       "style": "IPY_MODEL_f4654fbb701d49af8338c08d65608f85",
       "value": " 2101279/2101279 [01:46&lt;00:00, 13486.49 examples/s]"
      }
     },
     "94d31c1d0e1f4a2cb8c0887c0e189b46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bdd40adf999b4bd7a179d4c06d932b89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce3338bfac8e47718ff819f2d43c87b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf0f296316ae41cb88e8143943c29a6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfcc186a07414805964c70ff1ea17042": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2516454c3f2496aadd5cf6c2574c156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf0f296316ae41cb88e8143943c29a6a",
       "placeholder": "​",
       "style": "IPY_MODEL_15398f1325934918a23737ede99fd4e1",
       "value": "Map (num_proc=2): 100%"
      }
     },
     "d25f17c5b63543f3a52bb2752ce968d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db1383cb519c4893821684f647f15545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2516454c3f2496aadd5cf6c2574c156",
        "IPY_MODEL_60eeb2778f94429883fbc2bfe6628037",
        "IPY_MODEL_f3ccf9066c2e448588b2f9ef7b18a094"
       ],
       "layout": "IPY_MODEL_ce3338bfac8e47718ff819f2d43c87b2"
      }
     },
     "eccf44ff50fa49b99f8e702cd7e8af33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94d31c1d0e1f4a2cb8c0887c0e189b46",
       "max": 2101279.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45c63b6d9c7f4e5abafd8d9b6b6481ec",
       "value": 2101279.0
      }
     },
     "f3ccf9066c2e448588b2f9ef7b18a094": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d25f17c5b63543f3a52bb2752ce968d3",
       "placeholder": "​",
       "style": "IPY_MODEL_fa6a7565f77542359a038f1b1be789ca",
       "value": " 2781652/2781652 [04:08&lt;00:00, 11214.15 examples/s]"
      }
     },
     "f4654fbb701d49af8338c08d65608f85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f6b4a25c89b14094bd3dc5733ea854d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fa6a7565f77542359a038f1b1be789ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
